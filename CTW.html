<h1>Early-Stage Dementia Prediction using Convolutional Neural Networks</h1>

<p>This is a Project Site for Data Science 2016 at Olin College of Engineering</p>
<p>This website is intended to be an informative data visualization and tool and offer some potential directions and conclusions based on our model. It should NOT be used as an actual diagnostic tool.</p>

<h2>What is Dementia?</h2>
<p>"Dementia is not a specific disease. It's an overall term that describes a wide range of symptoms associated with a decline in memory or other thinking skills severe enough to reduce a person's ability to perform everyday tasks"[1] </p>

<p> Dementia is generally a progressive disease that[1]:</p>
<ul>
	<li>Affects more than an estimated 5 million individuals in the United States.</li>
	<li>6th Leading Cause of Death in the United States.</li>
	<li>Cannot be prevented, cured, or slowed.</li>
	<li>Less than half(45%) of these individuals have been actually diagnosed.</li>
</ul>

<p> Dementia is usually diagnosed based on a careful medical history, physical examination, laboratory tests, behavioral and functional observations, and recently brain imaging.It is caused by damage to the brain cells, disrupting their ability to communicate and thus function properly. In general dementia is only when 2 or more core mental functions: memory, language, visual perception, ability to focus, problem solving, and reasoning are impaired.[1] </p>


<h2>Use of Brain Imaging in Diagnosing Dementia</h2>
<p> The rise of brain imaging utilizing medical imaging technologies such as computer tomography(CT) and magnetic resonance imaging (MRI) has, according to the Neuroimaging Work Group of the Alzheimer's Association,"offer[ed] only relatively modest incremental benefits for the diagnosis of AD" due to the relatively high accuracy of present methods(~80%).[2] </p>

<p> From the extensive clinical research there have been multiple progression markers identified to be indicative of Alzheimer's[2]: </p>
<ul>
<li>General brain atrophy over time(from serial MRI).</li>
<ul>
	<li>Brain Boundary Shift Integral</li>
        <li>Ventricular CSF Measurements</li> 
        <li>Sample size estimates based on homogeneity of brain imaging data</li>
</ul>
<li>Atrophy in the Medial Temporal Lobe.</li>
<ul>
	<li>Hippocampus</li>
        <li>Etorhinal cortex</li>

</ul>	
</ul>

<h2>Project Overview</h2>
<p>
The goal of this project was to create both informative data visualizations and a data driven-tool using the data set we chose (<a href = "http://www.oasis-brains.org/">OASIS MRI Scans</a>). We used our model as both a predictive tool but also an informative one by creating saliency maps. 
</p>

<h3>Project Methods</h3>
<p> We started out by downsizing the image data since the neural network structure we are referencing typically works better with smaller images(we used data from <a href = "http://www.oasis-brains.org/">OASIS</a>). Specifically, we change "COR" images from 176*176 to 44*44; "SAG" images from 208*176 to 52*44; "TRA" images from 176*208 to 44*52. After data processing, we built a 6-layer convolutional neural network in a structure of "CONV-POOL-CONV-POOL-FULLYCONNECTED-SOFTMAX". We used stochastic gradient decent and back propagation in training our model. After 100 epochs of training, we got about 82% score in the test data.    
</p>

<p> Note that during our data processing, we also convert all the 'NAN' CDR value to 0 since most of the 'NAN' subject's age tends to be relatively young and we assume that their CDR is 0. That might cause some errors in our model though. However, since we only have 416 data entries and a large portion of them are 'NAN' in CDR, we finally decide to use the data anyway.
</p>

<p> To visualize our trainning, we used a method called saliency map. We basically used a black box to run through an image to create a series of black-boxed images. We then fed these images to our model and get their prediction probablities. And then compute the square differences between the original image and black-boxed images. Since these images have black box over different places, by computing the square differences, we can see how much the model is dependent on the part we are covering with the black box. Then we just placed the square errors into a matrix of the same size as the original image. We can use this matrix to visualize the matrix of square errors to see how important each part of the image.        
</p>

<p> Finally, we just put everything together and create a simple tool to predict the CDR of input MRI image and shows a saliency map of the image.
</p>

<h2>Results and Interpretation</h2>
<p>
A standard brain MRI can be taken from 3 views: Sagittal(from the side). Transverse(from the front/back), Horizontal(from the top), which offer different clarity of various brain structures. The data set was provided in the three different views and we created three different saliency maps to identify what our model was paying attention to. 
</p>
<p>
<img src="https://lh3.googleusercontent.com/-tQkDf5nY8o4/VuI3b7SuA7I/AAAAAAAAAfw/oSq0YCucji4acZGIMPlAyarDisij_XQWQ/s0/brains.jpg">
</p>
<p>
Figure 1: Reference Diagram for localized brain structures in MRI Images vs. Saliency map for final model, patients without dementia, amd patients with dementia in three views(horizontal,transverse,sagittal)
</p>
<p>
By comparing the images: 
<ul>
	<li> From the 2nd column of images(final map) we see that the model is actually paying attention to most of the brain with a special focus on the hippocampus and midbrain areas in the horizontal and transverse views, which matches clinical research. </li>
	<li> From the 3rd column (patients w/o dementia) the model highlights parts of the occipital lobe and cerebellum (horizontal), (),frontal lobe and cerebellum(sagittal). </li> 
	<li> From the 4th column (patients w/ dementia) the model highlights the hippocampus, midbrain, and ventricle areas (horizontal and transverse) and the hippocampus and occipital lobe in the sagittal view. </li>
</ul>
The model suggests that:
<ul>
	<li> The overall model is able to identify regions of interests validated by clinical research in the horizontal and transverse views but is unable to inside the sagittal view. </li>
	<li> When comparing the overall saliency map. we see that the model ends up paying attention to a lot of other features(most of the brain) which seem to indicate the model could be potentially be paying attention otdrive the overall brain volume. This could be potentially misleading without proper temporal data and suggests that the model is unable to differentiate between noise</li> 
	<li> Interestingly the sagittal view suggests that the occipital lobe and thalamas are viable features to detect dementia. This suggests a potentialrelationship not suggested by literature. </li>
</ul>
</p>

<h2>Predictive Model</h2>
<p>To use our model refer to the ReadMe in our <a href = "https://github.com/YuzhongHuang/DataScience16CTW">github_repository</a></p>

<h2>Project Members:</h2>
<p>Wilson Tang </p>                      
<p> Yuzhong Huang</p>

<h4>Citations and References</h4>
<p>
[1]- What Is Dementia? (n.d.). Retrieved March 10, 2016, from http://www.alz.org/what-is-dementia.asp
</p>
<p>
[2]-Weiner et al., 2005
M. Weiner, M. Albert, C. DeCarli, S. de Kosky, M. de Leon, N.L. Foster, N. Fox, R. Frank, R. Frackowiak, C. Jack, W. Jagust, D. Knopman, J. Morris, R.C. Petersen, E. Reiman, P. Scheltens, G. Small, H. Soininen, L. Thal, L. Wahlund, W. Thies, K. Khachaturian
The Use of MRI and PET for Clinical Diagnosis of Dementia and Investigation of Cognitive Impairment: A Consensus Report
Alzheimer's Association, Chicago, IL (2005)
</p>